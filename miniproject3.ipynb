{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "miniproject3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpa5QLrMIbsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXGYuN1AJIy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/COMP\\ 551\\ -\\ Mini\\ Project\\ 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emr4UyTUPDsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DASESkhWPRvc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58XDuLe6LBis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dropout, MaxPool2D, BatchNormalization, Dense, Activation\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import preprocessing as pre\n",
        "\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAngRXCln4CI",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbIzZRrPLJYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read Training Data\n",
        "x_train = pd.read_pickle('data/train_max_x')\n",
        "y_train = pd.read_csv(\"data/train_max_y.csv\").Label.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppiAbQ2nNsoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply image preprocessing\n",
        "x_train = pre.extract_digits(x_train)\n",
        "\n",
        "print(x_train[1])\n",
        "\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(20):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(255 - x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(y_train[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZO47nGEP9cd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimensions of image\n",
        "input_shape = (128,128,1)\n",
        "num_classes = 10\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XruWKnS9abQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Augmentation\n",
        "seed = 1\n",
        "batch_size=128\n",
        "datagen = ImageDataGenerator(horizontal_flip=False,\n",
        "                             vertical_flip=False,\n",
        "                             rotation_range=20,\n",
        "                             shear_range=0.10,\n",
        "                             validation_split=0.0)\n",
        "datagen.fit(x_train, seed=seed)\n",
        "train_iterator = datagen.flow(x_train, y_train, batch_size=batch_size, seed=seed)\n",
        "# val_iterator = datagen.flow(x_train, y_train, batch_size=batch_size, seed=seed, subset='validation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz5IBTSjnQLS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Our CNN Model\n",
        "model = keras.Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu'))\n",
        "model.add(MaxPool2D((2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(1024, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), activation='relu',padding='same'))\n",
        "model.add(Conv2D(1024, (3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOrATWlmQMDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16 Model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, (3,3), padding=\"same\", input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(256, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(512, (3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096,activation=\"relu\"))\n",
        "#model.add(Dense(4096,activation=\"relu\"))\n",
        "model.add(Dense(num_classes, activation=\"softmax\"))\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1YAP5cLQA6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit using Augmented Data\n",
        "history = model.fit_generator(train_iterator,\n",
        "                    # validation_data = val_iterator,\n",
        "                    epochs = 40)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzOuKGvqSX_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check if model was trained properly\n",
        "model.summary()\n",
        "train_loss, train_acc = model.evaluate(x_train, y_train, verbose=2)\n",
        "print('\\nTrain accuracy:', train_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XFLeR06ZbPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot Validation vs Training Accuracies against Epochs\n",
        "epochs = 80\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(10,10))\n",
        "# plt.plot(np.arange(0, epochs), history3.history[\"loss\"], label=\"train_loss\")\n",
        "# plt.plot(np.arange(0, epochs), history3.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, epochs), history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
        "plt.plot(np.arange(0, epochs), history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
        "plt.title(\"Training and Validation Accuracy on Dataset\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"our_cnn_80_epochs.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTUduFQyG_zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Test Data\n",
        "x_test = pd.read_pickle('data/test_max_x')\n",
        "x_test = pre.extract_digits(x_test)\n",
        "x_test = x_test.astype(float)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWnT0kP7L7VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions to CSV file\n",
        "predictions = np.argmax(model.evaluate(x_train, y_train, verbose=2), axis=1)\n",
        "df = pd.DataFrame(pd.Series(final_pred))\n",
        "df.to_csv('data/test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}